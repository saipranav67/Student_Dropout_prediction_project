# -*- coding: utf-8 -*-
"""IBM_SkillBuild_Student_DropOut_Prediction_Og.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FwJu9hwqg01wiysQd5ePmGAfnOBto5Ts

# ***importing data set***
"""

import pandas as pd
from google.colab import drive

drive.mount('/content/drive/')
data=pd.read_csv('/content/drive/MyDrive/IBM_project/IBM Dataset/data.csv',delimiter=';')

print(data.info())

data.head(10)

"""# **CLEANING DATA SET**

REMOVING UNWANTED COLUMNS
"""

# Columns to keep
columns_to_keep = [
    'Previous qualification (grade)', 'Admission grade', 'Age at enrollment',
    'Curricular units 1st sem (credited)', 'Curricular units 1st sem (enrolled)',
    'Curricular units 1st sem (evaluations)', 'Curricular units 1st sem (approved)',
    'Curricular units 1st sem (grade)', 'Curricular units 1st sem (without evaluations)',
    'Curricular units 2nd sem (credited)', 'Curricular units 2nd sem (enrolled)',
    'Curricular units 2nd sem (evaluations)', 'Curricular units 2nd sem (approved)',
    'Curricular units 2nd sem (grade)', 'Curricular units 2nd sem (without evaluations)',
    'Unemployment rate', 'Inflation rate', 'GDP', 'Target'
]

# Filter the dataset
filtered_data = data[columns_to_keep]
data=filtered_data

print(filtered_data.info())

filtered_data.head(10)

"""**Checking for null values**"""

print(filtered_data.isnull().sum())

"""# **Data Preprocessing**"""

from sklearn.preprocessing import LabelEncoder

# Initialize the label encoder
label_encoder = LabelEncoder()

# Encode the 'Target' column
filtered_data['Target'] = label_encoder.fit_transform(filtered_data['Target'])

# Check unique values after encoding
print("Unique values in the 'Target' column after encoding:")
print(filtered_data['Target'].unique())

# Check the mapping of original categories to encoded values
print("Mapping of original categories to encoded values:")
mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))
print(mapping)

# Verify the encoding
print(filtered_data['Target'].value_counts())

from sklearn.preprocessing import StandardScaler

# Initialize the StandardScaler
scaler = StandardScaler()

# Fit the scaler on the training data and transform the training data
X_train_scaled = scaler.fit_transform(X_train)

# Transform the test data using the fitted scaler
X_test_scaled = scaler.transform(X_test)

# Display the first 5 rows of the scaled training data
print("First 5 rows of the scaled training data:")
print(X_train_scaled[:5])

"""# **Exploratory Data Analysis (EDA)**"""

import matplotlib.pyplot as plt
import seaborn as sns

# Distribution of the target variable
plt.figure(figsize=(8, 6))
sns.countplot(data=filtered_data, x='Target')
plt.title('Distribution of Target Variable')
plt.xlabel('Target')
plt.ylabel('Count')
plt.xticks(ticks=[0, 1, 2], labels=['Dropout', 'Enrolled', 'Graduate'])
plt.show()

# Correlation matrix
plt.figure(figsize=(12, 10))
corr_matrix = filtered_data.corr()
sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Matrix')
plt.show()

# Histograms for numeric features
numeric_features = filtered_data.select_dtypes(include=['int64', 'float64']).columns

filtered_data[numeric_features].hist(bins=30, figsize=(20, 15))
plt.suptitle('Histograms of Numeric Features')
plt.show()

import pandas as pd

# Dropout counts and total counts for each semester
dropout_counts_1st_sem = filtered_data[filtered_data['Target'] == 0].groupby('Curricular units 1st sem (credited)').size()
total_counts_1st_sem = filtered_data.groupby('Curricular units 1st sem (credited)').size()
dropout_rate_1st_sem = dropout_counts_1st_sem / total_counts_1st_sem

dropout_counts_2nd_sem = filtered_data[filtered_data['Target'] == 0].groupby('Curricular units 2nd sem (credited)').size()
total_counts_2nd_sem = filtered_data.groupby('Curricular units 2nd sem (credited)').size()
dropout_rate_2nd_sem = dropout_counts_2nd_sem / total_counts_2nd_sem

# Create DataFrames for each semester
dropout_rate_1st_sem_df = pd.DataFrame({
    'Credits Credited': dropout_rate_1st_sem.index,
    'Dropout Rate 1st Sem': dropout_rate_1st_sem.values
})

dropout_rate_2nd_sem_df = pd.DataFrame({
    'Credits Credited': dropout_rate_2nd_sem.index,
    'Dropout Rate 2nd Sem': dropout_rate_2nd_sem.values
})

# Merge the two DataFrames
combined_df = pd.merge(dropout_rate_1st_sem_df, dropout_rate_2nd_sem_df, on='Credits Credited', how='outer')

import matplotlib.pyplot as plt
import seaborn as sns

# Plot scatter plot of credits credited vs. dropout rate for both semesters
plt.figure(figsize=(12, 8))

# Scatter plot for 1st semester
sns.scatterplot(data=combined_df, x='Credits Credited', y='Dropout Rate 1st Sem', color='blue', label='1st Semester', s=100, alpha=0.6)

# Scatter plot for 2nd semester
sns.scatterplot(data=combined_df, x='Credits Credited', y='Dropout Rate 2nd Sem', color='red', label='2nd Semester', s=100, alpha=0.6)

# Add titles and labels
plt.title('Credits Credited vs. Dropout Rate for Each Semester', fontsize=14)
plt.xlabel('Credits Credited', fontsize=12)
plt.ylabel('Dropout Rate', fontsize=12)
plt.legend()
plt.grid(True)
plt.show()

"""# **Modelling**

**Data splitting**
"""

from sklearn.model_selection import train_test_split

# Split the data into features (X) and target (y)
X = filtered_data.drop(columns=['Target'])
y = filtered_data['Target']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Display the shapes of the training and testing sets
print(f"Training set shape: {X_train.shape}, {y_train.shape}")
print(f"Testing set shape: {X_test.shape}, {y_test.shape}")

"""**Model Training and Evaluation**"""

from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report

# Initialize the scaler and model
scaler = StandardScaler()
model = LogisticRegression(max_iter=1000, random_state=42)

# Scale the training and test data
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Train the model
model.fit(X_train_scaled, y_train)

# Predict on the test data
y_pred = model.predict(X_test_scaled)

# Calculate and display the accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")

# Display the classification report
print("Classification Report:")
print(classification_report(y_test, y_pred))

"""**Hyperparameter Tuning**"""

from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import accuracy_score, classification_report
from joblib import dump
import pandas as pd

# Assuming 'data' is your dataset and 'Target' is your target variable

# Separate features and target
X = data.drop(columns=['Target'])
y = data['Target']

# Split data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and fit the scaler on training data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Define the parameter grid for GridSearchCV
param_grid = {
    'C': [0.1, 1, 10, 100],
    'solver': ['lbfgs', 'liblinear', 'saga']
}

# Initialize the logistic regression model
log_reg = LogisticRegression(max_iter=1000, random_state=42)

# Initialize GridSearchCV with the logistic regression model and parameter grid
grid_search = GridSearchCV(log_reg, param_grid, cv=5, scoring='accuracy')

# Fit GridSearchCV on the training data
grid_search.fit(X_train_scaled, y_train)

# Get the best model from GridSearchCV
best_model = grid_search.best_estimator_

# Predict on the test data using the best model
y_pred_best = best_model.predict(X_test_scaled)

# Calculate the accuracy with the best model
best_accuracy = accuracy_score(y_test, y_pred_best)

# Display the best parameters, best cross-validation accuracy, and the accuracy with the best model
print(f"Best Parameters: {grid_search.best_params_}")
print(f"Best Cross-Validation Accuracy: {grid_search.best_score_:.2f}")
print(f"Accuracy with Best Model: {best_accuracy:.2f}")

# Display the classification report with the best model
target_mapping = {0: 'Dropout', 1: 'Enrolled', 2: 'Graduate'}
print("Classification Report with Best Model:")
print(classification_report(y_test, y_pred_best, target_names=target_mapping.values()))

"""# **Evaluation**

**Saving The Model**
"""

from joblib import dump

# Save the best model
dump(best_model, '/content/drive/MyDrive/IBM_project/IBM Dataset/best_logistic_model.joblib')

# Save the scaler
dump(scaler, '/content/drive/MyDrive/IBM_project/IBM Dataset/scaler.joblib')

"""**model evaluation and cross validation**"""

from sklearn.model_selection import cross_val_score
from joblib import load

# Load the scaler and model
scaler = load('/content/drive/MyDrive/IBM_project/IBM Dataset/scaler.joblib')
best_model = load('/content/drive/MyDrive/IBM_project/IBM Dataset/best_logistic_model.joblib')


# Scale the entire feature set
X_scaled = scaler.transform(X)

# Perform cross-validation
cv_scores = cross_val_score(best_model, X_scaled, y, cv=5, scoring='accuracy')

# Display the cross-validation scores and the mean score
print(f"Cross-Validation Scores: {cv_scores}")
print(f"Mean Cross-Validation Accuracy: {cv_scores.mean():.2f}")

"""**Feature Importance Analysis**"""

# Get the feature names
feature_names = X.columns

# Get the coefficients of the model
coefficients = best_model.coef_[0]

# Create a DataFrame for feature importance
feature_importance = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefficients})
feature_importance = feature_importance.sort_values(by='Coefficient', ascending=False)

# Display the top features
print("Top positive features:")
print(feature_importance.head(10))
print("\nTop negative features:")
print(feature_importance.tail(10))

"""# **Results Compilation and Saving**

**Compiling and Saving Analysis Results**
"""

import json

# Get cross-validation scores from GridSearchCV
cv_scores = grid_search.cv_results_['mean_test_score']

# Get feature importance for LogisticRegression (absolute values of coefficients)
importances = abs(best_model.coef_[0])
feature_names = X.columns

# Create a DataFrame to hold feature importances
feature_importance = pd.DataFrame({
    'Feature': feature_names,
    'Importance': importances
})

# Sort features by importance
feature_importance = feature_importance.sort_values(by='Importance', ascending=False)

# Prepare the results dictionary
analysis_results = {
    'Cross-Validation Scores': cv_scores.tolist(),
    'Mean Cross-Validation Accuracy': cv_scores.mean(),
    'Top Positive Features': feature_importance.head(10).to_dict('records'),
    'Top Negative Features': feature_importance.tail(10).to_dict('records')
}

# Save the results to a JSON file
with open('/content/drive/MyDrive/IBM_project/IBM Dataset/analysis_results.json', 'w') as f:
    json.dump(analysis_results, f, indent=4)

"""# **Making Predictions on New Data using a trained model**

**Sample Test 1**
"""

import pandas as pd
from joblib import load

# Example new data values for prediction
new_data_example = [[12, 10.5, 19, 3, 8, 6, 7.5, 15, 3, 6, 5, 4, 9, 2, 8, 0.5, 0.3, 30000]]

# Convert new data to DataFrame with correct columns
columns = ['Previous qualification (grade)', 'Admission grade', 'Age at enrollment',
           'Curricular units 1st sem (credited)', 'Curricular units 1st sem (enrolled)',
           'Curricular units 1st sem (evaluations)', 'Curricular units 1st sem (approved)',
           'Curricular units 1st sem (grade)', 'Curricular units 1st sem (without evaluations)',
           'Curricular units 2nd sem (credited)', 'Curricular units 2nd sem (enrolled)',
           'Curricular units 2nd sem (evaluations)', 'Curricular units 2nd sem (approved)',
           'Curricular units 2nd sem (grade)', 'Curricular units 2nd sem (without evaluations)',
           'Unemployment rate', 'Inflation rate', 'GDP']

new_data_df = pd.DataFrame(new_data_example, columns=columns)

# Verify the shape
print(new_data_df.shape)

# Load the scaler and scale the new data
loaded_scaler = load('/content/drive/MyDrive/IBM_project/IBM Dataset/scaler.joblib')
new_data_scaled = loaded_scaler.transform(new_data_df)

# Load the trained model and make predictions
loaded_model = load('/content/drive/MyDrive/IBM_project/IBM Dataset/best_logistic_model.joblib')
predictions = loaded_model.predict(new_data_scaled)

# Assuming 'label_encoder' is already defined
# Reverse transform the predictions to get the original labels
decoded_predictions = label_encoder.inverse_transform(predictions)

print("Predictions:", decoded_predictions)

"""**Sample Test 2**"""

from joblib import load
import pandas as pd

# Load the scaler and model
loaded_scaler = load('/content/drive/MyDrive/IBM_project/IBM Dataset/scaler.joblib')
loaded_model = load('/content/drive/MyDrive/IBM_project/IBM Dataset/best_logistic_model.joblib')

# Create multiple test cases for dropout scenarios
dropout_cases = pd.DataFrame({
    'Previous qualification (grade)': [5.0, 4.0, 3.0],  # Low previous qualification grades
    'Admission grade': [5.0, 4.0, 3.0],                # Low admission grades
    'Age at enrollment': [25, 26, 27],                 # Age at enrollment
    'Curricular units 1st sem (credited)': [0, 0, 0],  # No credited units in the first semester
    'Curricular units 1st sem (enrolled)': [10, 10, 10], # High number of enrolled units in the first semester
    'Curricular units 1st sem (evaluations)': [5, 4, 3], # Low number of evaluations in the first semester
    'Curricular units 1st sem (approved)': [1, 1, 1],    # Low number of approved units in the first semester
    'Curricular units 1st sem (grade)': [5.0, 4.0, 3.0], # Low grades in the first semester
    'Curricular units 1st sem (without evaluations)': [5, 6, 7], # High number of units without evaluations in the first semester
    'Curricular units 2nd sem (credited)': [0, 0, 0],    # No credited units in the second semester
    'Curricular units 2nd sem (enrolled)': [10, 10, 10], # High number of enrolled units in the second semester
    'Curricular units 2nd sem (evaluations)': [5, 4, 3], # Low number of evaluations in the second semester
    'Curricular units 2nd sem (approved)': [1, 1, 1],    # Low number of approved units in the second semester
    'Curricular units 2nd sem (grade)': [5.0, 4.0, 3.0], # Low grades in the second semester
    'Curricular units 2nd sem (without evaluations)': [5, 6, 7], # High number of units without evaluations in the second semester
    'Unemployment rate': [15.0, 15.0, 15.0],           # High unemployment rate
    'Inflation rate': [5.0, 5.0, 5.0],                 # High inflation rate
    'GDP': [1.0, 1.0, 1.0]                             # Low GDP
})

# Scale the dropout cases data
dropout_cases_scaled = loaded_scaler.transform(dropout_cases)

# Predict using the loaded model
dropout_predictions = loaded_model.predict(dropout_cases_scaled)

# Map the predictions back to the original categories
dropout_prediction_labels = label_encoder.inverse_transform(dropout_predictions)

for i, prediction in enumerate(dropout_prediction_labels):
    print(f"Prediction for Dropout Case {i+1}: {prediction}")

"""**Sample Test 3**"""

from joblib import load
import pandas as pd

# Load the scaler and model
loaded_scaler = load('/content/drive/MyDrive/IBM_project/IBM Dataset/scaler.joblib')
loaded_model = load('/content/drive/MyDrive/IBM_project/IBM Dataset/best_logistic_model.joblib')

# Create multiple test cases for graduate scenarios
graduate_cases = pd.DataFrame({
    'Previous qualification (grade)': [15.0, 14.0, 13.0],  # High previous qualification grades
    'Admission grade': [18.0, 17.0, 16.0],                # High admission grades
    'Age at enrollment': [18, 19, 20],                    # Age at enrollment
    'Curricular units 1st sem (credited)': [8, 8, 8],     # Many credited units in the first semester
    'Curricular units 1st sem (enrolled)': [6, 6, 6],     # Low number of enrolled units in the first semester
    'Curricular units 1st sem (evaluations)': [7, 7, 7],  # High number of evaluations in the first semester
    'Curricular units 1st sem (approved)': [7, 7, 7],     # High number of approved units in the first semester
    'Curricular units 1st sem (grade)': [18.0, 17.0, 16.0],# High grades in the first semester
    'Curricular units 1st sem (without evaluations)': [0, 0, 0], # Low number of units without evaluations in the first semester
    'Curricular units 2nd sem (credited)': [8, 8, 8],     # Many credited units in the second semester
    'Curricular units 2nd sem (enrolled)': [6, 6, 6],     # Low number of enrolled units in the second semester
    'Curricular units 2nd sem (evaluations)': [7, 7, 7],  # High number of evaluations in the second semester
    'Curricular units 2nd sem (approved)': [7, 7, 7],     # High number of approved units in the second semester
    'Curricular units 2nd sem (grade)': [18.0, 17.0, 16.0],# High grades in the second semester
    'Curricular units 2nd sem (without evaluations)': [0, 0, 0], # Low number of units without evaluations in the second semester
    'Unemployment rate': [5.0, 5.0, 5.0],                 # Low unemployment rate
    'Inflation rate': [2.0, 2.0, 2.0],                    # Low inflation rate
    'GDP': [3.0, 3.0, 3.0]                                # High GDP
})

# Scale the graduate cases data
graduate_cases_scaled = loaded_scaler.transform(graduate_cases)

# Predict using the loaded model
graduate_predictions = loaded_model.predict(graduate_cases_scaled)

# Map the predictions back to the original categories
graduate_prediction_labels = label_encoder.inverse_transform(graduate_predictions)

for i, prediction in enumerate(graduate_prediction_labels):
    print(f"Prediction for Graduate Case {i+1}: {prediction}")